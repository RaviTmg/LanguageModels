{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-21\n",
    "\n",
    "Initial experiments with n-gram models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " 'ngram',\n",
       " 'rnn',\n",
       " 'split']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)\n",
    "reload(wp.split)\n",
    "dir(wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of phantastes, by george macdonald  this ebook is for the use of anyone \n"
     ]
    }
   ],
   "source": [
    "# load the text used to train the models\n",
    "\n",
    "trainfile = 'data/all-train.txt'\n",
    "\n",
    "with open(trainfile, 'rb') as f:\n",
    "    s_train = f.read()\n",
    "    s_train = s_train.strip()\n",
    "    s_train = s_train.lower()\n",
    "    f.close()\n",
    "    \n",
    "s_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the training text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of phantastes, by george macdonald  this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  yet is it a little window, that loo\n",
      "\n",
      "o and come in affright as though tossed back and forth between the swords of the uhlans and the fusillade of the brigades of kempt, best, pack, and rylandt; the worst of hand-to-hand conflicts is the\n",
      "\n",
      ", the sight of birds, tender shadows, agitated branches, and a soul made of sweetness, of faith, of candor, of hope, of aspiration, and of illusion.  cosette had left the convent when she was still al\n",
      "\n",
      "prepossessing exterior.  coarse paper, coarsely folded--the very sight of certain missives is displeasing.  the letter which basque had brought was of this sort.  it smelled of tobacco.  marius recogn\n",
      "\n",
      "s.  the ring of the fort drew him with stronger fascination during that hot august weather.  standing, or as his headmaster would have said, \"mooning\" by the gate, and looking into that enclosed and s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nchars = len(s_train)\n",
    "nsamples = 5\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_train[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split some text into sentences\n",
    "\n",
    "This shows how the text was split up into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you think so?\n",
      "\n",
      "but the face, which throbbed with fluctuating and pulsatory visibility--not from changes in the light it reflected, but from changes in its own conditions of reflecting power, the alterations being from within, not from without--it was horrible.\n",
      "\n",
      "they are very fond of having fun with the thick people, as they call you; for, like most children, they like fun better than anything else.\n",
      "\n",
      "not a living creature crossed my way.\n",
      "\n",
      "but my attention was first and chiefly attracted by a group of fairies near the cottage, who were talking together around what seemed a last dying primrose.\n"
     ]
    }
   ],
   "source": [
    "sentences = wp.split.get_sentences(s_train[0:50000]) # use first 50k chars instead of all 6mb\n",
    "nsamples = 5\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, nsamples)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split some text up into tokens, which is how the models will process it\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', 'you', 'think', 'so', '?']\n",
      "\n",
      "['but', 'the', 'face', ',', 'which', 'throbbed', 'with', 'fluctuating', 'and', 'pulsatory', 'visibility', '--', 'not', 'from', 'changes', 'in', 'the', 'light', 'it', 'reflected', ',', 'but', 'from', 'changes', 'in', 'its', 'own', 'conditions', 'of', 'reflecting', 'power', ',', 'the', 'alterations', 'being', 'from', 'within', ',', 'not', 'from', 'without', '--', 'it', 'was', 'horrible', '.']\n",
      "\n",
      "['they', 'are', 'very', 'fond', 'of', 'having', 'fun', 'with', 'the', 'thick', 'people', ',', 'as', 'they', 'call', 'you', ';', 'for', ',', 'like', 'most', 'children', ',', 'they', 'like', 'fun', 'better', 'than', 'anything', 'else', '.']\n",
      "\n",
      "['not', 'a', 'living', 'creature', 'crossed', 'my', 'way', '.']\n",
      "\n",
      "['but', 'my', 'attention', 'was', 'first', 'and', 'chiefly', 'attracted', 'by', 'a', 'group', 'of', 'fairies', 'near', 'the', 'cottage', ',', 'who', 'were', 'talking', 'together', 'around', 'what', 'seemed', 'a', 'last', 'dying', 'primrose', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    sample = str(sample) # convert utf-8 to plain strings (just to avoid u'foo')\n",
    "    tokens = wp.split.get_tokens(sample)\n",
    "    print(tokens)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Load Models\n",
    "\n",
    "Load models if they have been saved in pickle files, otherwise train them on the training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model object\n",
      "train model\n",
      "tokenize words\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/ngram-model-basic-n-2.pickle\n",
      "create model object\n",
      "train model\n",
      "tokenize words\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/ngram-model-basic-n-3.pickle\n",
      "load model: models/rnn.pickle\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#. put in a pandas table? use to store results also? \n",
    "\n",
    "#. better to just have a list of model objects with these as properties? \n",
    "\n",
    "mlist = [\n",
    "    ['n-gram (n=2)', 'ngram-model-basic-n-2', ngram.NgramModel, {'n':2}],\n",
    "    ['n-gram (n=3)', 'ngram-model-basic-n-3', ngram.NgramModel, {'n':3}],\n",
    "    ['rnn', 'rnn', rnn.RnnModel, {}],\n",
    "]\n",
    "\n",
    "#.. wasteful to tokenize s_train to words each time - pass it tokens instead of string...\n",
    "\n",
    "for m in mlist:\n",
    "    modelname = m[0]\n",
    "    modelfile = 'models/' + m[1] + '.pickle'\n",
    "    modelclass = m[2]\n",
    "    modelparams = m[3]\n",
    "\n",
    "    # load existing model, or create, train, and save one\n",
    "    if os.path.isfile(modelfile):\n",
    "        print(\"load model: \" + modelfile)\n",
    "        model = modelclass.load(modelfile) # static method\n",
    "    else:\n",
    "        print(\"create model object\")\n",
    "        model = modelclass(**modelparams)\n",
    "\n",
    "        print(\"train model\")\n",
    "        model.train(s_train)\n",
    "\n",
    "        print(\"save model: \" + modelfile)\n",
    "        model.save(modelfile)\n",
    "\n",
    "    m.append(model)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models\n",
    "\n",
    "Now that we have some trained models, let's test them against some held-out data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' but could see nothing from which such a shadow should fall.\\n\\nwhat did i see?\\n\\ni saw the strangest figure; vague, shadowy, almost transparent, in the central parts, and gradually deepening in substance towards the outside, until it ended in extremities capable of casting such a shadow as fell from the hand, through the awful fingers of which i now saw the moon.\\n\\novercome with the mingling of terror and joy, i lay for some time almost insensible.\\n\\ni turned my head, but without moving otherwise, f'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfile = 'data/all-test.txt'\n",
    "\n",
    "with open(testfile, 'rb') as f:\n",
    "    s_test = f.read()\n",
    "    s_test = s_test.strip()\n",
    "    s_test = s_test.lower()\n",
    "    f.close()\n",
    "    \n",
    "s_test[5000:5500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split text into tuples of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize the test text\n",
    "test_tokens = tokenize.word_tokenize(s_test) # eg ['the','dog','barked',...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chamber', 'where'), ('where', 'the'), ('the', 'secretary'), ('secretary', 'stood'), ('stood', ','), (',', 'the'), ('the', 'first'), ('first', 'lights'), ('lights', 'that'), ('that', 'had'), ('had', 'been'), ('been', 'there'), ('there', 'for'), ('for', 'many'), ('many', 'a'), ('a', 'year'), ('year', ';'), (';', 'for'), ('for', ','), (',', 'since')]\n"
     ]
    }
   ],
   "source": [
    "# now group the tokens into tuples\n",
    "#. will want to iterate over ntokens_per_tuple?\n",
    "ntokens_per_tuple = 2\n",
    "tokenlists = [test_tokens[i:] for i in range(ntokens_per_tuple)]\n",
    "test_tuples = zip(*tokenlists) # eg [['the','dog'], ['dog','barked'], ...]\n",
    "print(test_tuples[100:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('greville', 'macdonald') None\n",
      "('macdonald', '.') this\n",
      "('.', 'september') the\n",
      "('september', '1905.') ,\n",
      "('1905.', 'phantastes') None\n",
      "('phantastes', 'a') ,\n",
      "('a', 'faerie') little\n",
      "('faerie', 'romance') bulwarks\n",
      "('romance', 'phantastes') ,\n",
      "('phantastes', 'from') ,\n",
      "('from', 'their') the\n",
      "('their', 'fount') own\n",
      "('fount', 'all') None\n",
      "('all', 'shapes') the\n",
      "('shapes', 'deriving') ,\n",
      "('deriving', ',') None\n",
      "(',', 'in') and\n",
      "('in', 'new') the\n",
      "('new', 'habiliments') york\n",
      "('habiliments', 'can') of\n",
      "('can', 'quickly') not\n",
      "('greville', 'macdonald') None\n",
      "('macdonald', '.') ***\n",
      "('.', 'september') the\n",
      "('september', '1905.') ,\n",
      "('1905.', 'phantastes') None\n",
      "('phantastes', 'a') ,\n",
      "('a', 'faerie') little\n",
      "('faerie', 'romance') invade\n",
      "('romance', 'phantastes') ,\n",
      "('phantastes', 'from') ,\n",
      "('from', 'their') the\n",
      "('their', 'fount') own\n",
      "('fount', 'all') None\n",
      "('all', 'shapes') the\n",
      "('shapes', 'deriving') ,\n",
      "('deriving', ',') None\n",
      "(',', 'in') and\n",
      "('in', 'new') the\n",
      "('new', 'habiliments') york\n",
      "('habiliments', 'can') .\n",
      "('can', 'quickly') not\n",
      "('greville', 'macdonald') None\n",
      "('macdonald', '.') None\n",
      "('.', 'september') None\n",
      "('september', '1905.') None\n",
      "('1905.', 'phantastes') None\n",
      "('phantastes', 'a') None\n",
      "('a', 'faerie') None\n",
      "('faerie', 'romance') None\n",
      "('romance', 'phantastes') None\n",
      "('phantastes', 'from') None\n",
      "('from', 'their') None\n",
      "('their', 'fount') None\n",
      "('fount', 'all') None\n",
      "('all', 'shapes') None\n",
      "('shapes', 'deriving') None\n",
      "('deriving', ',') None\n",
      "(',', 'in') None\n",
      "('in', 'new') None\n",
      "('new', 'habiliments') None\n",
      "('habiliments', 'can') None\n",
      "('can', 'quickly') None\n"
     ]
    }
   ],
   "source": [
    "for m in mlist:\n",
    "    model = m[-1] #. yuck\n",
    "    i = 0\n",
    "    for tuple in test_tuples:\n",
    "        prompt = tuple[:-1]\n",
    "        y_actual = tuple[-1]\n",
    "        y_predict = model.predict(prompt)\n",
    "        print(tuple, y_predict)\n",
    "        i += 1\n",
    "        if i>20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
