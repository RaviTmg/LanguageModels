{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordly\n",
    "## Experiment 2016-12-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial experiments with n-gram model - setting up architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os.path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " 'ngram',\n",
       " 'rnn',\n",
       " 'split']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "reload(wp)\n",
    "print('done')\n",
    "dir(wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wp.ngram.NgramModel instance at 0x000000001F249DC8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wp import ngram, rnn\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)\n",
    "model = ngram.NgramModel(2) # bigram\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__doc__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__str__',\n",
       " '_d',\n",
       " 'get_random',\n",
       " 'increment',\n",
       " 'load',\n",
       " 'n',\n",
       " 'predict',\n",
       " 'save',\n",
       " 'train']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainfile = 'data/all-train.txt'\n",
    "\n",
    "with open(trainfile, 'rb') as f:\n",
    "    s_train = f.read()\n",
    "    s_train = s_train.strip()\n",
    "    s_train = s_train.lower()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of phantastes, by george macdonald  this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  yet is it a little window, that loo\n",
      "\n",
      "o and come in affright as though tossed back and forth between the swords of the uhlans and the fusillade of the brigades of kempt, best, pack, and rylandt; the worst of hand-to-hand conflicts is the\n",
      "\n",
      ", the sight of birds, tender shadows, agitated branches, and a soul made of sweetness, of faith, of candor, of hope, of aspiration, and of illusion.  cosette had left the convent when she was still al\n",
      "\n",
      "prepossessing exterior.  coarse paper, coarsely folded--the very sight of certain missives is displeasing.  the letter which basque had brought was of this sort.  it smelled of tobacco.  marius recogn\n",
      "\n",
      "s.  the ring of the fort drew him with stronger fascination during that hot august weather.  standing, or as his headmaster would have said, \"mooning\" by the gate, and looking into that enclosed and s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show some samples of the training text\n",
    "nchars = len(s_train)\n",
    "nsamples = 5\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_train[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i crossed the rivulet, and accompanied it, keeping the footpath on its right bank, until it led me, as i expected, into the wood.\n",
      "\n",
      "it caused a new sensation.\n",
      "\n",
      "indeed, there were more instruments at work about her than there could have been sparks in her.\n",
      "\n",
      "it is a mere matter of relation.\n",
      "\n",
      "but the door of a little cupboard in the centre especially attracted my interest, as if there lay the secret of this long-hidden world.\n"
     ]
    }
   ],
   "source": [
    "# split some text into sentences and show a few - \n",
    "# this shows how the text was split up into train, validate, and test sets.\n",
    "sentences = wp.split.get_sentences(s_train[0:50000]) # use first 50k instead of all 6mb (slow)\n",
    "nsamples = 5\n",
    "l = random.sample(sentences, nsamples)\n",
    "print('\\n\\n'.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: models/ngram-model-basic-n-2.pickle\n",
      "load model: models/ngram-model-basic-n-3.pickle\n",
      "load model: models/rnn.pickle\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#. put in a pandas table? use to store results also? \n",
    "\n",
    "mlist = [\n",
    "    ['n-gram (n=2)', 'ngram-model-basic-n-2', ngram.NgramModel, {'n':2}],\n",
    "    ['n-gram (n=3)', 'ngram-model-basic-n-3', ngram.NgramModel, {'n':3}],\n",
    "    ['rnn', 'rnn', rnn.RnnModel, {}],\n",
    "]\n",
    "\n",
    "for m in mlist:\n",
    "    modelname = m[0]\n",
    "    modelfile = 'models/' + m[1] + '.pickle'\n",
    "    modelclass = m[2]\n",
    "    modelparams = m[3]\n",
    "\n",
    "    # load existing model, or create, train, and save one\n",
    "    if os.path.isfile(modelfile):\n",
    "        print(\"load model: \" + modelfile)\n",
    "        model = modelclass.load(modelfile) # static method\n",
    "    else:        \n",
    "        model = modelclass(**modelparams) # constructor\n",
    "\n",
    "        #print(\"read file: \" + trainfile)\n",
    "        #f = open(trainfile, 'rb')\n",
    "        #s = f.read()\n",
    "        #s = s.strip()\n",
    "        #s = s.lower()\n",
    "        #f.close()\n",
    "\n",
    "        print(\"train model\")\n",
    "        model.train(s)\n",
    "\n",
    "        print(\"save model: \" + modelfile)\n",
    "        model.save(modelfile)\n",
    "\n",
    "    m.append(model)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = 'data/all-test.txt'\n",
    "\n",
    "f = open(infile, 'rb')\n",
    "s = f.read()\n",
    "s = s.strip()\n",
    "s = s.lower()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('greville', 'macdonald') None\n",
      "('macdonald', '.') this\n",
      "('.', 'september') the\n",
      "('september', '1905.') ,\n",
      "('1905.', 'phantastes') None\n",
      "('phantastes', 'a') ,\n",
      "('a', 'faerie') little\n",
      "('faerie', 'romance') bulwarks\n",
      "('romance', 'phantastes') ,\n",
      "('phantastes', 'from') ,\n",
      "('from', 'their') the\n",
      "('their', 'fount') own\n",
      "('fount', 'all') None\n",
      "('all', 'shapes') the\n",
      "('shapes', 'deriving') ,\n",
      "('deriving', ',') None\n",
      "(',', 'in') and\n",
      "('in', 'new') the\n",
      "('new', 'habiliments') york\n",
      "('habiliments', 'can') of\n",
      "('can', 'quickly') not\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fa9523a0a8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "# walk through file with tokenizer\n",
    "#print s[:1000]\n",
    "\n",
    "from nltk import tokenize\n",
    "words = tokenize.word_tokenize(s)\n",
    "wlist = [words[i:] for i in range(n)]\n",
    "i=0\n",
    "for words in zip(*wlist):\n",
    "    prompt = words[:-1]\n",
    "    y_actual = words[-1]\n",
    "    y_predict = m.predict(prompt)\n",
    "    print words, y_predict\n",
    "    i+=1\n",
    "    if i>20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
