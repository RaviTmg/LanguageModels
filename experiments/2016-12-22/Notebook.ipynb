{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-22\n",
    "\n",
    "Refining test architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Training Data\n",
    "2. Explore Training Data\n",
    "3. Load / Train Models\n",
    "4. Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wp.rnn' from '../../src\\wp\\rnn.pyc'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge raw text files, convert to plain strings, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the raw data files into one and remove non-ascii characters (nltk complains otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file created.\n"
     ]
    }
   ],
   "source": [
    "data.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the merged file by sentences into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has been split into train, validate, and test files.\n"
     ]
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Phantastes, by George MacDonald  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re\n",
      "\n",
      "to be vanquished, retreated; but Wellington shouted, \"Up, Guards, and aim straight!\" The red regiment of English guards, lying flat behind the hedges, sprang up, a cloud of grape-shot riddled the tric\n",
      "\n",
      "xcept that geometrical point, the _I_; bringing everything back to the soul-atom; expanding everything in God, entangling all activity, from summit to base, in the obscurity of a dizzy mechanism, atta\n",
      "\n",
      "y, or to speak more accurately, that same evening, as Marius left the table, and was on the point of withdrawing to his study, having a case to look over, Basque handed him a letter saying: \"The perso\n",
      "\n",
      "ay evening in January, the lonely valley had been a desirable place to him; he had watched the green battlements in summer and winter weather, had seen the heaped mounds rising dimly amidst the drifti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 5\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And off they set, after some new mischief.\n",
      "\n",
      "Primrose is gone.\n",
      "\n",
      "But how then do you come to live here?\n",
      "\n",
      "He looked up, and lo!\n",
      "\n",
      "It contained many wondrous tales of Fairy Land, and olden times, and the Knights of King Arthurs table.\n"
     ]
    }
   ],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, 5)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntokens 10369\n",
      "[';', 'as', 'if', 'we', 'were', 'not', 'good', 'enough', 'to', 'look', 'at', 'her', ',', 'and', 'she', 'was', ',', 'the', 'proud', 'thing', '!', '--', 'served', 'her', 'right', '!', 'Oh', ',', 'Pocket', ',', 'Pocket', ',', 'said', 'I', ';', 'but', 'by', 'this', 'time', 'the', 'party', 'which', 'had', 'gone', 'towards', 'the', 'house', ',', 'rushed', 'out', 'again', ',', 'shouting', 'and', 'screaming', 'with', 'laughter', '.', 'Half', 'of', 'them', 'were', 'on', 'the', 'cats', 'back', ',', 'and', 'half', 'held', 'on', 'by', 'her', 'fur', 'and', 'tail', ',', 'or', 'ran', 'beside', 'her', ';', 'till', ',', 'more', 'coming', 'to', 'their', 'help', ',', 'the', 'furious', 'cat', 'was', 'held', 'fast', ';', 'and', 'they', 'proceeded']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tokens('merged', 50000) # look at first 50k characters\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[8000:8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train / Load Models\n",
    "\n",
    "Load models if they have been saved in pickle files, otherwise train them on the training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get sequence of training tokens (slow)\n",
    "train_tokens = data.tokens('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function first\n",
    "def encode_params(params):\n",
    "    \"\"\"\n",
    "    Encode a dictionary of parameters as a string to be stored in a filename.\n",
    "    e.g. {'n':3,'b':1.2} => 'n-3,b-1.2'\n",
    "    \"\"\"\n",
    "    s = str(params)\n",
    "    s = s.replace(':','-')\n",
    "    s = s.replace(\"'\",'')\n",
    "    s = s.replace('{','')\n",
    "    s = s.replace('}','')\n",
    "    s = s.replace(' ','')\n",
    "    s = '(' + s + ')'\n",
    "    return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: models/NgramModel-(n-2).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-3).pickle\n",
      "load model: models/RnnModel-().pickle\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#. put in a pandas table? use to store results also? \n",
    "\n",
    "#model_list = [\n",
    "#    ['n-gram (n=2)', 'ngram-model-basic-n-2', wp.ngram.NgramModel, {'n':2}],\n",
    "#    ['n-gram (n=3)', 'ngram-model-basic-n-3', wp.ngram.NgramModel, {'n':3}],\n",
    "#    ['rnn', 'rnn', wp.rnn.RnnModel, {}],\n",
    "#]\n",
    "model_list = [\n",
    "    [wp.ngram.NgramModel, {'n':2}],\n",
    "    [wp.ngram.NgramModel, {'n':3}],\n",
    "#    [wp.ngram.NgramModel, {'n':4}],\n",
    "    [wp.rnn.RnnModel, {}],\n",
    "]\n",
    "\n",
    "models = []\n",
    "for modelclass, modelparams in model_list:\n",
    "\n",
    "    # load existing model, or create, train, and save one\n",
    "    sparams = encode_params(modelparams)\n",
    "    modelfile = 'models/' + modelclass.__name__ + '-' + sparams + '.pickle'\n",
    "    if os.path.isfile(modelfile):\n",
    "        print(\"load model: \" + modelfile)\n",
    "        model = modelclass.load(modelfile) # static method\n",
    "    else:\n",
    "        print(\"create model object\")\n",
    "        model = modelclass(**modelparams)\n",
    "\n",
    "        print(\"train model\")\n",
    "        model.train(train_tokens)\n",
    "\n",
    "        print(\"save model: \" + modelfile)\n",
    "        model.save(modelfile)\n",
    "\n",
    "    models.append(model)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Models\n",
    "\n",
    "Now that we have some trained models, let's test them against some held-out data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split text into tuples of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'chamber'), ('chamber', 'where'), ('where', 'the'), ('the', 'secretary'), ('secretary', 'stood'), ('stood', ','), (',', 'the'), ('the', 'first'), ('first', 'lights'), ('lights', 'that'), ('that', 'had'), ('had', 'been'), ('been', 'there'), ('there', 'for'), ('for', 'many'), ('many', 'a'), ('a', 'year'), ('year', ';'), (';', 'for'), ('for', ',')]\n"
     ]
    }
   ],
   "source": [
    "#. will want to iterate over ntokens_per_tuple?\n",
    "\n",
    "ntokens_per_tuple = 2\n",
    "test_tuples = data.tuples('test', ntokens_per_tuple)\n",
    "print(test_tuples[100:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram (n=2)\n",
      "nright/total=8/100\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=7/100\n",
      "\n",
      "rnn\n",
      "nright/total=0/100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imax = 100\n",
    "for model in models:\n",
    "    print(model.name)\n",
    "    i = 0\n",
    "    nright = 0\n",
    "    for tuple in test_tuples:\n",
    "        prompt = tuple[:-1]\n",
    "        actual = tuple[-1]\n",
    "        prediction = model.predict(prompt)\n",
    "        if actual==prediction:\n",
    "            nright += 1\n",
    "        i += 1\n",
    "        if i>imax: break\n",
    "    print(\"nright/total=%d/%d\" % (nright, imax))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
