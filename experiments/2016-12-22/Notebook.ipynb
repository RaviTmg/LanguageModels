{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-22\n",
    "\n",
    "Refining test architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Training Data\n",
    "2. Explore Training Data\n",
    "3. Load / Train Models\n",
    "4. Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wp.rnn' from '../../src\\wp\\rnn.pyc'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge raw text files, convert to plain strings, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the raw data files into one and remove non-ascii characters (nltk complains otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file already exists.\n"
     ]
    }
   ],
   "source": [
    "data.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the merged file by sentences into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has already been split.\n"
     ]
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Phantastes, by George MacDonald  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re\n",
      "\n",
      "to be vanquished, retreated; but Wellington shouted, \"Up, Guards, and aim straight!\" The red regiment of English guards, lying flat behind the hedges, sprang up, a cloud of grape-shot riddled the tric\n",
      "\n",
      "xcept that geometrical point, the _I_; bringing everything back to the soul-atom; expanding everything in God, entangling all activity, from summit to base, in the obscurity of a dizzy mechanism, atta\n",
      "\n",
      "y, or to speak more accurately, that same evening, as Marius left the table, and was on the point of withdrawing to his study, having a case to look over, Basque handed him a letter saying: \"The perso\n",
      "\n",
      "ay evening in January, the lonely valley had been a desirable place to him; he had watched the green battlements in summer and winter weather, had seen the heaped mounds rising dimly amidst the drifti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 5\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And off they set, after some new mischief.\n",
      "\n",
      "Primrose is gone.\n",
      "\n",
      "But how then do you come to live here?\n",
      "\n",
      "He looked up, and lo!\n",
      "\n",
      "It contained many wondrous tales of Fairy Land, and olden times, and the Knights of King Arthurs table.\n"
     ]
    }
   ],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, 5)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntokens 10369\n",
      "[';', 'as', 'if', 'we', 'were', 'not', 'good', 'enough', 'to', 'look', 'at', 'her', ',', 'and', 'she', 'was', ',', 'the', 'proud', 'thing', '!', '--', 'served', 'her', 'right', '!', 'Oh', ',', 'Pocket', ',', 'Pocket', ',', 'said', 'I', ';', 'but', 'by', 'this', 'time', 'the', 'party', 'which', 'had', 'gone', 'towards', 'the', 'house', ',', 'rushed', 'out', 'again', ',', 'shouting', 'and', 'screaming', 'with', 'laughter', '.', 'Half', 'of', 'them', 'were', 'on', 'the', 'cats', 'back', ',', 'and', 'half', 'held', 'on', 'by', 'her', 'fur', 'and', 'tail', ',', 'or', 'ran', 'beside', 'her', ';', 'till', ',', 'more', 'coming', 'to', 'their', 'help', ',', 'the', 'furious', 'cat', 'was', 'held', 'fast', ';', 'and', 'they', 'proceeded']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tokens('merged', 50000) # look at first 50k characters\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[8000:8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train / Load Models\n",
    "\n",
    "Load models if they have been saved in pickle files, otherwise train them on the training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function\n",
    "def encode_params(params):\n",
    "    \"\"\"\n",
    "    Encode a dictionary of parameters as a string to be stored in a filename.\n",
    "    e.g. {'n':3,'b':1.2} => 'n-3,b-1.2'\n",
    "    \"\"\"\n",
    "    s = str(params)\n",
    "    s = s.replace(':','-')\n",
    "    s = s.replace(\"'\",'')\n",
    "    s = s.replace('{','')\n",
    "    s = s.replace('}','')\n",
    "    s = s.replace(' ','')\n",
    "    s = '(' + s + ')'\n",
    "    return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#.. will want to put this and next cell into fns \n",
    "# so can call within a loop over nchars to train on\n",
    "#. could include nchars in sparams\n",
    "#. might need to use an a\n",
    "\n",
    "# get sequence of training tokens (slow)\n",
    "train_tokens = data.tokens('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: models/NgramModel-(n-2).pickle\n",
      "load model: models/NgramModel-(n-3).pickle\n",
      "load model: models/NgramModel-(n-4).pickle\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# define models to test\n",
    "model_list = [\n",
    "    [wp.ngram.NgramModel, {'n':2}],\n",
    "    [wp.ngram.NgramModel, {'n':3}],\n",
    "    [wp.ngram.NgramModel, {'n':4}],\n",
    "    #[wp.rnn.RnnModel, {}],\n",
    "]\n",
    "\n",
    "# iterate over models\n",
    "models = []\n",
    "for modelclass, modelparams in model_list:\n",
    "\n",
    "    # load existing model, or create, train, and save one\n",
    "    sparams = encode_params(modelparams)\n",
    "    modelfile = 'models/' + modelclass.__name__ + '-' + sparams + '.pickle'\n",
    "    if os.path.isfile(modelfile):\n",
    "        print(\"load model: \" + modelfile)\n",
    "        model = modelclass.load(modelfile) # static method\n",
    "    else:\n",
    "        print(\"create model object\")\n",
    "        model = modelclass(**modelparams)\n",
    "\n",
    "        print(\"train model\")\n",
    "        model.train(train_tokens)\n",
    "\n",
    "        print(\"save model: \" + modelfile)\n",
    "        model.save(modelfile)\n",
    "\n",
    "    models.append(model)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Models\n",
    "\n",
    "Now that we have some trained models, let's test them against some held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the test tokens\n",
    "test_tokens = data.tokens('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function\n",
    "def get_tuples(tokens, ntokens_per_tuple):\n",
    "    \"\"\"\n",
    "    Group sequences of tokens together.\n",
    "    e.g. ['the','dog','barked',...]=>[['the','dog'],['dog','barked'],...]\n",
    "    \"\"\"\n",
    "    tokenlists = [tokens[i:] for i in range(ntokens_per_tuple)]\n",
    "    tuples = zip(*tokenlists)\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram (n=2)\n",
      "nright/total=239/1000 = 0.239000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=176/1000 = 0.176000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=53/1000 = 0.053000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run test on the models\n",
    "npredictions = 1000\n",
    "k = 3 # number of tokens to predict\n",
    "for model in models:\n",
    "    print(model.name)\n",
    "    n = model.n\n",
    "    test_tuples = get_tuples(test_tokens, n) # group tokens into sequences\n",
    "    i = 0\n",
    "    nright = 0\n",
    "    for tuple in test_tuples:\n",
    "        prompt = tuple[:-1]\n",
    "        actual = tuple[-1]\n",
    "        prediction = model.predict(prompt, k)\n",
    "        if prediction: # can be None\n",
    "            predicted_tokens = [pair[0] for pair in prediction]\n",
    "            if actual in predicted_tokens:\n",
    "                nright += 1\n",
    "        i += 1\n",
    "        if i>npredictions: break\n",
    "    print(\"nright/total=%d/%d = %f\" % (nright, imax, nright/imax))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
