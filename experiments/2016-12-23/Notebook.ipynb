{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-23\n",
    "\n",
    "Loop over training size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Data\n",
    "2. Explore Data\n",
    "3. Train Models\n",
    "4. Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wp.rnn' from '../../src\\wp\\rnn.pyc'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge raw text files, convert to plain strings, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the raw data files into one and remove non-ascii characters (nltk complains otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file already exists.\n"
     ]
    }
   ],
   "source": [
    "data.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the merged file by sentences into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has already been split.\n"
     ]
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Phantastes, by George MacDonald  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re\n",
      "\n",
      "to be vanquished, retreated; but Wellington shouted, \"Up, Guards, and aim straight!\" The red regiment of English guards, lying flat behind the hedges, sprang up, a cloud of grape-shot riddled the tric\n",
      "\n",
      "xcept that geometrical point, the _I_; bringing everything back to the soul-atom; expanding everything in God, entangling all activity, from summit to base, in the obscurity of a dizzy mechanism, atta\n",
      "\n",
      "y, or to speak more accurately, that same evening, as Marius left the table, and was on the point of withdrawing to his study, having a case to look over, Basque handed him a letter saying: \"The perso\n",
      "\n",
      "ay evening in January, the lonely valley had been a desirable place to him; he had watched the green battlements in summer and winter weather, had seen the heaped mounds rising dimly amidst the drifti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 5\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And off they set, after some new mischief.\n",
      "\n",
      "Primrose is gone.\n",
      "\n",
      "But how then do you come to live here?\n",
      "\n",
      "He looked up, and lo!\n",
      "\n",
      "It contained many wondrous tales of Fairy Land, and olden times, and the Knights of King Arthurs table.\n"
     ]
    }
   ],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, 5)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntokens 10369\n",
      "[';', 'as', 'if', 'we', 'were', 'not', 'good', 'enough', 'to', 'look', 'at', 'her', ',', 'and', 'she', 'was', ',', 'the', 'proud', 'thing', '!', '--', 'served', 'her', 'right', '!', 'Oh', ',', 'Pocket', ',', 'Pocket', ',', 'said', 'I', ';', 'but', 'by', 'this', 'time', 'the', 'party', 'which', 'had', 'gone', 'towards', 'the', 'house', ',', 'rushed', 'out', 'again', ',', 'shouting', 'and', 'screaming', 'with', 'laughter', '.', 'Half', 'of', 'them', 'were', 'on', 'the', 'cats', 'back', ',', 'and', 'half', 'held', 'on', 'by', 'her', 'fur', 'and', 'tail', ',', 'or', 'ran', 'beside', 'her', ';', 'till', ',', 'more', 'coming', 'to', 'their', 'help', ',', 'the', 'furious', 'cat', 'was', 'held', 'fast', ';', 'and', 'they', 'proceeded']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tokens('merged', 50000) # look at first 50k characters\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[8000:8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Models\n",
    "\n",
    "Train models on the training tokens, or else load them if they have been saved in pickle files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function\n",
    "def encode_params(params):\n",
    "    \"\"\"\n",
    "    Encode a dictionary of parameters as a string to be stored in a filename.\n",
    "    e.g. {'n':3,'b':1.2} => 'n-3,b-1.2'\n",
    "    \"\"\"\n",
    "    s = str(params)\n",
    "    s = s.replace(':','-')\n",
    "    s = s.replace(\"'\",'')\n",
    "    s = s.replace('{','')\n",
    "    s = s.replace('}','')\n",
    "    s = s.replace(' ','')\n",
    "    s = '(' + s + ')'\n",
    "    return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#.. will want to put this and next cell into fns \n",
    "# so can call within a loop over nchars to train on\n",
    "#. could include nchars in sparams\n",
    "#. might need to use an alist instead of dict, to preserve order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_models(nchars=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # get sequence of training tokens (slow)\n",
    "    train_tokens = data.tokens('train', nchars)\n",
    "\n",
    "    # define models to test\n",
    "    model_list = [\n",
    "        [wp.ngram.NgramModel, {'n':2}],\n",
    "        [wp.ngram.NgramModel, {'n':3}],\n",
    "        [wp.ngram.NgramModel, {'n':4}],\n",
    "        #[wp.rnn.RnnModel, {}],\n",
    "    ]\n",
    "\n",
    "    # iterate over models\n",
    "    models = []\n",
    "    for modelclass, modelparams in model_list:\n",
    "\n",
    "        # load existing model, or create, train, and save one\n",
    "        sparams = encode_params(modelparams)\n",
    "        modelfile = 'models/' + modelclass.__name__ + '-' + sparams + '.pickle'\n",
    "#        if os.path.isfile(modelfile):\n",
    "#            print(\"load model: \" + modelfile)\n",
    "#            model = modelclass.load(modelfile) # static method\n",
    "#        else:\n",
    "        if 1:\n",
    "            print(\"create model object\")\n",
    "            model = modelclass(**modelparams)\n",
    "\n",
    "            print(\"train model\")\n",
    "            model.train(train_tokens)\n",
    "\n",
    "            print(\"save model: \" + modelfile)\n",
    "            model.save(modelfile)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    print(\"done\")\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Models\n",
    "\n",
    "Now that we have some trained models, let's test them against some held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function\n",
    "def get_tuples(tokens, ntokens_per_tuple):\n",
    "    \"\"\"\n",
    "    Group sequences of tokens together.\n",
    "    e.g. ['the','dog','barked',...]=>[['the','dog'],['dog','barked'],...]\n",
    "    \"\"\"\n",
    "    tokenlists = [tokens[i:] for i in range(ntokens_per_tuple)]\n",
    "    tuples = zip(*tokenlists)\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_models(models, nchars=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # get the test tokens\n",
    "    test_tokens = data.tokens('test', nchars)\n",
    "\n",
    "    # run test on the models\n",
    "    npredictions = 1000\n",
    "    k = 3 # number of tokens to predict\n",
    "    for model in models:\n",
    "        print(model.name)\n",
    "        n = model.n\n",
    "        test_tuples = get_tuples(test_tokens, n) # group tokens into sequences\n",
    "        i = 0\n",
    "        nright = 0\n",
    "        for tuple in test_tuples:\n",
    "            prompt = tuple[:-1]\n",
    "            actual = tuple[-1]\n",
    "            prediction = model.predict(prompt, k)\n",
    "            if prediction: # can be None\n",
    "                predicted_tokens = [pair[0] for pair in prediction]\n",
    "                if actual in predicted_tokens:\n",
    "                    nright += 1\n",
    "            i += 1\n",
    "            if i>npredictions: break\n",
    "        print(\"nright/total=%d/%d = %f\" % (nright, npredictions, nright/npredictions))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-2).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-3).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=0/1000 = 0.000000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=0/1000 = 0.000000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=0/1000 = 0.000000\n",
      "\n",
      "\n",
      "5000\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-2).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-3).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=36/1000 = 0.036000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=3/1000 = 0.003000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=0/1000 = 0.000000\n",
      "\n",
      "\n",
      "10000\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-2).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-3).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=97/1000 = 0.097000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=13/1000 = 0.013000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=3/1000 = 0.003000\n",
      "\n",
      "\n",
      "20000\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-2).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-3).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=128/1000 = 0.128000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=31/1000 = 0.031000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=6/1000 = 0.006000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nchars in (1000,5000,10000,20000):\n",
    "    print(nchars)\n",
    "    models = train_models(nchars)\n",
    "    test_models(models, nchars)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
