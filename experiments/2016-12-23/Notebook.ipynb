{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-23\n",
    "\n",
    "Loop over training size, plot learning curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Data\n",
    "2. Explore Data\n",
    "3. Analyze Models\n",
    "4. Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wp.analyze' from '../../src\\wp\\analyze.py'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)\n",
    "reload(wp.analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge raw text files, convert to plain strings, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the raw data files into one and remove non-ascii characters (nltk complains otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw files have already been merged.\n"
     ]
    }
   ],
   "source": [
    "data.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the merged file by sentences into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has already been split.\n"
     ]
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Phantastes, by George MacDonald  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re\n",
      "\n",
      "to be vanquished, retreated; but Wellington shouted, \"Up, Guards, and aim straight!\" The red regiment of English guards, lying flat behind the hedges, sprang up, a cloud of grape-shot riddled the tric\n",
      "\n",
      "xcept that geometrical point, the _I_; bringing everything back to the soul-atom; expanding everything in God, entangling all activity, from summit to base, in the obscurity of a dizzy mechanism, atta\n",
      "\n",
      "y, or to speak more accurately, that same evening, as Marius left the table, and was on the point of withdrawing to his study, having a case to look over, Basque handed him a letter saying: \"The perso\n",
      "\n",
      "ay evening in January, the lonely valley had been a desirable place to him; he had watched the green battlements in summer and winter weather, had seen the heaped mounds rising dimly amidst the drifti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 5\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And off they set, after some new mischief.\n",
      "\n",
      "Primrose is gone.\n",
      "\n",
      "But how then do you come to live here?\n",
      "\n",
      "He looked up, and lo!\n",
      "\n",
      "It contained many wondrous tales of Fairy Land, and olden times, and the Knights of King Arthurs table.\n"
     ]
    }
   ],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, 5)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntokens 10369\n",
      "[';', 'as', 'if', 'we', 'were', 'not', 'good', 'enough', 'to', 'look', 'at', 'her', ',', 'and', 'she', 'was', ',', 'the', 'proud', 'thing', '!', '--', 'served', 'her', 'right', '!', 'Oh', ',', 'Pocket', ',', 'Pocket', ',', 'said', 'I', ';', 'but', 'by', 'this', 'time', 'the', 'party', 'which', 'had', 'gone', 'towards', 'the', 'house', ',', 'rushed', 'out', 'again', ',', 'shouting', 'and', 'screaming', 'with', 'laughter', '.', 'Half', 'of', 'them', 'were', 'on', 'the', 'cats', 'back', ',', 'and', 'half', 'held', 'on', 'by', 'her', 'fur', 'and', 'tail', ',', 'or', 'ran', 'beside', 'her', ';', 'till', ',', 'more', 'coming', 'to', 'their', 'help', ',', 'the', 'furious', 'cat', 'was', 'held', 'fast', ';', 'and', 'they', 'proceeded']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tokens('merged', 50000) # look at first 50k characters\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[8000:8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Models\n",
    "\n",
    "Train models on the training tokens and test them on the test tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define models to test\n",
    "model_list = [\n",
    "    [wp.ngram.NgramModel, {'n':2}],\n",
    "    [wp.ngram.NgramModel, {'n':3}],\n",
    "    [wp.ngram.NgramModel, {'n':4}],\n",
    "    #[wp.rnn.RnnModel, {}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "load model: models/NgramModel-(nchars-1000,n-2).pickle\n",
      "load model: models/NgramModel-(nchars-1000,n-3).pickle\n",
      "load model: models/NgramModel-(nchars-1000,n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=1/1000 = 0.001000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=0/1000 = 0.000000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=0/1000 = 0.000000\n",
      "\n",
      "\n",
      "10000\n",
      "load model: models/NgramModel-(nchars-10000,n-2).pickle\n",
      "load model: models/NgramModel-(nchars-10000,n-3).pickle\n",
      "load model: models/NgramModel-(nchars-10000,n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=99/1000 = 0.099000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=13/1000 = 0.013000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=3/1000 = 0.003000\n",
      "\n",
      "\n",
      "100000\n",
      "load model: models/NgramModel-(nchars-100000,n-2).pickle\n",
      "load model: models/NgramModel-(nchars-100000,n-3).pickle\n",
      "load model: models/NgramModel-(nchars-100000,n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=190/1000 = 0.190000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=85/1000 = 0.085000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=14/1000 = 0.014000\n",
      "\n",
      "\n",
      "1000000\n",
      "load model: models/NgramModel-(nchars-1000000,n-2).pickle\n",
      "load model: models/NgramModel-(nchars-1000000,n-3).pickle\n",
      "load model: models/NgramModel-(nchars-1000000,n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=234/1000 = 0.234000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=133/1000 = 0.133000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=36/1000 = 0.036000\n",
      "\n",
      "\n",
      "6000000\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(nchars-6000000,n-2).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(nchars-6000000,n-3).pickle\n",
      "create model object\n",
      "train model\n",
      "get ngrams\n",
      "add ngrams to model\n",
      "save model: models/NgramModel-(nchars-6000000,n-4).pickle\n",
      "done\n",
      "n-gram (n=2)\n",
      "nright/total=239/1000 = 0.239000\n",
      "\n",
      "n-gram (n=3)\n",
      "nright/total=174/1000 = 0.174000\n",
      "\n",
      "n-gram (n=4)\n",
      "nright/total=53/1000 = 0.053000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nchars in (1000,10000,100000,1000000,6000000):\n",
    "    print(nchars)\n",
    "    models = wp.analyze.train_models(model_list, data, nchars)\n",
    "    results = wp.analyze.test_models(models, data, nchars)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
