{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-23\n",
    "\n",
    "Loop over training size, plot learning curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Data\n",
    "2. Explore Data\n",
    "3. Analyze Models\n",
    "4. Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wp.analyze' from '../../src\\wp\\analyze.pyc'>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.util)\n",
    "reload(wp.model)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)\n",
    "reload(wp.analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge raw text files, convert to plain strings, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the raw data files into one and remove non-ascii characters (nltk complains otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw files have been merged.\n"
     ]
    }
   ],
   "source": [
    "data.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the merged file by sentences into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has been split into train, validate, and test files.\n"
     ]
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Les Misrables, by Victor Hugo  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-us\n",
      "\n",
      "ese names, Droit-Mur and Aumarais, are very ancient; the streets which bear them are very much more ancient still. Aumarais Lane was called Maugout Lane; the Rue Droit-Mur was called the Rue des glant\n",
      "\n",
      "y uneasy and very suspicious, and that while seeking to ferret out a man like Ppin or Morey, they might very readily discover a man like Jean Valjean.  Jean Valjean had made up his mind to quit Paris,\n",
      "\n",
      "ooked mistily about him. First he recognized the doctor with an unmistakable frown; then his glance fell upon me, and he looked relieved. But suddenly his colour changed, and he tried to raise himself\n",
      "\n",
      "e articles to magazines, in pathetic ignorance of the trade. He felt the immense difficulty of the career of literature without clearly understanding it; the battle was happily in a mist, so that the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 5\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To villages where he found no schoolmaster, he quoted once more the people of Queyras: \"Do you know how they manage?\"\n",
      "\n",
      "Those who had and those who lacked knocked at M. Myriel's door,--the latter in search of the alms which the former came to deposit.\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, 5)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntokens 10556\n",
      "['hard', 'bishopric', 'for', 'a', 'good', 'bishop', 'the', 'bishop', 'did', 'not', 'omit', 'his', 'pastoral', 'visits', 'because', 'he', 'had', 'converted', 'his', 'carriage', 'into', 'alms', '.', 'END', 'the', 'diocese', 'of', 'd', '--', '--', 'is', 'a', 'fatiguing', 'one', '.', 'END', 'there', 'are', 'very', 'few', 'plains', 'and', 'a', 'great', 'many', 'mountains', ';', 'hardly', 'any', 'roads', ',', 'as', 'we', 'have', 'just', 'seen', ';', 'thirty-two', 'curacies', ',', 'forty-one', 'vicarships', ',', 'and', 'two', 'hundred', 'and', 'eighty-five', 'auxiliary', 'chapels', '.', 'END', 'to', 'visit', 'all', 'these', 'is', 'quite', 'a', 'task', '.', 'END', 'the', 'bishop', 'managed', 'to', 'do', 'it', '.', 'END', 'he', 'went', 'on', 'foot', 'when', 'it', 'was', 'in', 'the', 'neighborhood']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tokens('merged', 50000) # look at first 50k characters\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[8000:8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Models\n",
    "\n",
    "Train models on the training tokens and test them on the test tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define models to test\n",
    "modelspecs = [\n",
    "    [wp.ngram.NgramModel, {'n':1}],\n",
    "    [wp.ngram.NgramModel, {'n':2}],\n",
    "    [wp.ngram.NgramModel, {'n':3}],\n",
    "    [wp.ngram.NgramModel, {'n':4}],\n",
    "#    [wp.rnn.RnnModel, {}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntraining_chars 1000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "get complete stream of test tokens, nchars=1000\n",
      "get tuples, n=1\n",
      "n-gram (n=1): accuracy = nright/total = 44/185 = 0.237838\n",
      "get tuples, n=2\n",
      "n-gram (n=2): accuracy = nright/total = 23/184 = 0.125000\n",
      "get tuples, n=3\n",
      "n-gram (n=3): accuracy = nright/total = 12/183 = 0.065574\n",
      "get tuples, n=4\n",
      "n-gram (n=4): accuracy = nright/total = 1/182 = 0.005495\n",
      "\n",
      "ntraining_chars 10000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "get complete stream of test tokens, nchars=10000\n",
      "get tuples, n=1\n",
      "n-gram (n=1): accuracy = nright/total = 187/1001 = 0.186813\n",
      "get tuples, n=2\n",
      "n-gram (n=2): accuracy = nright/total = 205/1001 = 0.204795\n",
      "get tuples, n=3\n",
      "n-gram (n=3): accuracy = nright/total = 106/1001 = 0.105894\n",
      "get tuples, n=4\n",
      "n-gram (n=4): accuracy = nright/total = 33/1001 = 0.032967\n",
      "\n",
      "ntraining_chars 100000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "get complete stream of test tokens, nchars=100000\n",
      "get tuples, n=1\n",
      "n-gram (n=1): accuracy = nright/total = 119/1001 = 0.118881\n",
      "get tuples, n=2\n",
      "n-gram (n=2): accuracy = nright/total = 299/1001 = 0.298701\n",
      "get tuples, n=3\n",
      "n-gram (n=3): accuracy = nright/total = 182/1001 = 0.181818\n",
      "get tuples, n=4\n",
      "n-gram (n=4): accuracy = nright/total = 79/1001 = 0.078921\n",
      "\n",
      "ntraining_chars 1000000\n",
      "create model object\n",
      "get complete stream of training tokens, nchars=1000000\n",
      "train model\n",
      "get ngrams, n=1\n",
      "add ngrams to model\n",
      "save model\n",
      "create model object\n",
      "train model\n",
      "get ngrams, n=2\n",
      "add ngrams to model\n",
      "save model\n",
      "create model object\n",
      "train model\n",
      "get ngrams, n=3\n",
      "add ngrams to model\n",
      "save model\n",
      "create model object\n",
      "train model\n",
      "get ngrams, n=4\n",
      "add ngrams to model\n",
      "save model\n",
      "get complete stream of test tokens, nchars=1000000\n",
      "get tuples, n=1\n",
      "n-gram (n=1): accuracy = nright/total = 119/1001 = 0.118881\n",
      "get tuples, n=2\n",
      "n-gram (n=2): accuracy = nright/total = 350/1001 = 0.349650\n",
      "get tuples, n=3\n",
      "n-gram (n=3): accuracy = nright/total = 372/1001 = 0.371628\n",
      "get tuples, n=4\n",
      "n-gram (n=4): accuracy = nright/total = 330/1001 = 0.329670\n",
      "\n",
      "ntraining_chars 6000000\n",
      "create model object\n",
      "get complete stream of training tokens, nchars=6000000\n",
      "train model\n",
      "get ngrams, n=1\n",
      "add ngrams to model\n",
      "save model\n",
      "create model object\n",
      "train model\n",
      "get ngrams, n=2\n",
      "add ngrams to model\n",
      "save model\n",
      "create model object\n",
      "train model\n",
      "get ngrams, n=3\n",
      "add ngrams to model\n",
      "save model\n",
      "create model object\n",
      "train model\n",
      "get ngrams, n=4\n",
      "add ngrams to model\n",
      "save model\n",
      "get complete stream of test tokens, nchars=6000000\n",
      "get tuples, n=1\n",
      "n-gram (n=1): accuracy = nright/total = 119/1001 = 0.118881\n",
      "get tuples, n=2\n",
      "n-gram (n=2): accuracy = nright/total = 342/1001 = 0.341658\n",
      "get tuples, n=3\n",
      "n-gram (n=3): accuracy = nright/total = 382/1001 = 0.381618\n",
      "get tuples, n=4\n",
      "n-gram (n=4): accuracy = nright/total = 350/1001 = 0.349650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if output table already exists, skip this step\n",
    "#try:\n",
    "#    rows\n",
    "#except:\n",
    "if 1:\n",
    "    modelfolder = '../../data/models'\n",
    "    #. should be ntraining_tokens\n",
    "    nchars_list = (1000,10000,100000,1000000,6000000)\n",
    "    #nchars_list = (1000,10000,100000)\n",
    "    rows = []\n",
    "    npredictions_max = 1000\n",
    "    k = 3 # predict top k tokens\n",
    "    for nchars in nchars_list:\n",
    "        print('ntraining_chars', nchars)\n",
    "        models = wp.analyze.init_models(modelspecs, modelfolder, data, nchars)\n",
    "        results = wp.analyze.test_models(models, data, npredictions_max, k, nchars)\n",
    "        print()\n",
    "        row = [nchars] + results\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nchars</th>\n",
       "      <th>n-gram (n=1)</th>\n",
       "      <th>n-gram (n=2)</th>\n",
       "      <th>n-gram (n=3)</th>\n",
       "      <th>n-gram (n=4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.237838</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.005495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.204795</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.032967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.078921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>0.371628</td>\n",
       "      <td>0.329670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000000</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.341658</td>\n",
       "      <td>0.381618</td>\n",
       "      <td>0.349650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nchars  n-gram (n=1)  n-gram (n=2)  n-gram (n=3)  n-gram (n=4)\n",
       "0     1000      0.237838      0.125000      0.065574      0.005495\n",
       "1    10000      0.186813      0.204795      0.105894      0.032967\n",
       "2   100000      0.118881      0.298701      0.181818      0.078921\n",
       "3  1000000      0.118881      0.349650      0.371628      0.329670\n",
       "4  6000000      0.118881      0.341658      0.381618      0.349650"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nchars'] + [model.name for model in models]\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>1000000</th>\n",
       "      <th>6000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n-gram (n=1)</th>\n",
       "      <td>0.237838</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-gram (n=2)</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.204795</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>0.341658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-gram (n=3)</th>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.371628</td>\n",
       "      <td>0.381618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-gram (n=4)</th>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>0.349650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1000      10000     100000    1000000   6000000\n",
       "n-gram (n=1)  0.237838  0.186813  0.118881  0.118881  0.118881\n",
       "n-gram (n=2)  0.125000  0.204795  0.298701  0.349650  0.341658\n",
       "n-gram (n=3)  0.065574  0.105894  0.181818  0.371628  0.381618\n",
       "n-gram (n=4)  0.005495  0.032967  0.078921  0.329670  0.349650"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = df.transpose()\n",
    "dft.columns = nchars_list\n",
    "dft2 = dft.drop('nchars',axis=0)\n",
    "dft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(dft2.columns, dft2.ix[0])\n",
    "plt.plot(dft2.columns, dft2.ix[1])\n",
    "plt.plot(dft2.columns, dft2.ix[2])\n",
    "plt.plot(dft2.columns, dft2.ix[3])\n",
    "#plt.legend(loc='best')\n",
    "plt.legend(loc=(1.1,0.5))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Training set size (chars)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram (n=1)\n",
      "a and seeking somewhere of in bobbie the END\n",
      "\n",
      "bad a and it END\n",
      "\n",
      "occupant good one off a lord me the seemed expressed to case valjean in once safely youth something been de . . END\n",
      "\n",
      "by something he us was with . a then be will END\n",
      "\n",
      "by foot in when with in , word and at or the from fairs as , you whenever word for the was which some , plot seemed me on unknown END\n",
      "\n",
      "\n",
      "n-gram (n=2)\n",
      "who ought to the matter too much ; and all her pretty nigh hand . END\n",
      "\n",
      "it was nothing really had seen everywhere parallel rows of rum , and poorly , and sacrificing no longer find to you 're free from the project gutenberg-tm mission of the animal spirits , the foundation of these mingled in courtyards , with them bowed to which are there can get up the white one person conscientiously and let me ! END\n",
      "\n",
      "he began in debt to grant succor from the middle of the troops , and kissed him . END\n",
      "\n",
      "the 21st of age . END\n",
      "\n",
      "the one episode of bread , what ? '' END\n",
      "\n",
      "\n",
      "n-gram (n=3)\n",
      "surely that was always closed . END\n",
      "\n",
      "'whence come you ? -- you know what it is a matter of _cant_ , mademoiselle gillenormand , the daughter mademoiselle lanoire , and the park had fallen in love . END\n",
      "\n",
      "'you know my own account , in that way . END\n",
      "\n",
      "was looking very hard at toad to see mr. lattaker ? '' END\n",
      "\n",
      "knowing the children in disguise , with a bit , '' said old marshall 's chair , with a stick of sealing-wax and seemed as though two immense pockets of his love to flowers . END\n",
      "\n",
      "\n",
      "n-gram (n=4)\n",
      "surely , this saying of a peasant is a fine man . '' END\n",
      "\n",
      "'whence come you ? ' END\n",
      "\n",
      "'you know my bedroom . END\n",
      "\n",
      "was that all her reward ? END\n",
      "\n",
      "knowing the sort of satisfaction which an armorer would experience on recognizing his factory mark on a knife , and god defend the right . '' END\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nsentences = 5\n",
    "for model in models:\n",
    "    print(model.name)\n",
    "    for seed in range(nsentences):\n",
    "        random.seed(seed)\n",
    "        tokens = model.generate()\n",
    "        if tokens:\n",
    "            s = ' '.join(tokens)\n",
    "            print(s)\n",
    "            print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
