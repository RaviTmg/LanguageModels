{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-23\n",
    "\n",
    "Loop over training size, plot learning curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Data\n",
    "2. Explore Data\n",
    "3. Analyze Models\n",
    "4. Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing wp (and nltk)...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# import wp modules (can be slow)\n",
    "import sys; sys.path.append('../../src')\n",
    "print('importing wp (and nltk)...')\n",
    "import wp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wp.analyze' from '../../src\\wp\\analyze.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)\n",
    "reload(wp.analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge raw text files, convert to plain strings, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the raw data files into one and remove non-ascii characters (nltk complains otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw files have already been merged.\n"
     ]
    }
   ],
   "source": [
    "data.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the merged file by sentences into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has already been split.\n"
     ]
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Phantastes, by George MacDonald  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re\n",
      "\n",
      "to be vanquished, retreated; but Wellington shouted, \"Up, Guards, and aim straight!\" The red regiment of English guards, lying flat behind the hedges, sprang up, a cloud of grape-shot riddled the tric\n",
      "\n",
      "xcept that geometrical point, the _I_; bringing everything back to the soul-atom; expanding everything in God, entangling all activity, from summit to base, in the obscurity of a dizzy mechanism, atta\n",
      "\n",
      "y, or to speak more accurately, that same evening, as Marius left the table, and was on the point of withdrawing to his study, having a case to look over, Basque handed him a letter saying: \"The perso\n",
      "\n",
      "ay evening in January, the lonely valley had been a desirable place to him; he had watched the green battlements in summer and winter weather, had seen the heaped mounds rising dimly amidst the drifti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 5\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And off they set, after some new mischief.\n",
      "\n",
      "Primrose is gone.\n",
      "\n",
      "But how then do you come to live here?\n",
      "\n",
      "He looked up, and lo!\n",
      "\n",
      "It contained many wondrous tales of Fairy Land, and olden times, and the Knights of King Arthurs table.\n"
     ]
    }
   ],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(0)\n",
    "samples = random.sample(sentences, 5)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntokens 10369\n",
      "[';', 'as', 'if', 'we', 'were', 'not', 'good', 'enough', 'to', 'look', 'at', 'her', ',', 'and', 'she', 'was', ',', 'the', 'proud', 'thing', '!', '--', 'served', 'her', 'right', '!', 'Oh', ',', 'Pocket', ',', 'Pocket', ',', 'said', 'I', ';', 'but', 'by', 'this', 'time', 'the', 'party', 'which', 'had', 'gone', 'towards', 'the', 'house', ',', 'rushed', 'out', 'again', ',', 'shouting', 'and', 'screaming', 'with', 'laughter', '.', 'Half', 'of', 'them', 'were', 'on', 'the', 'cats', 'back', ',', 'and', 'half', 'held', 'on', 'by', 'her', 'fur', 'and', 'tail', ',', 'or', 'ran', 'beside', 'her', ';', 'till', ',', 'more', 'coming', 'to', 'their', 'help', ',', 'the', 'furious', 'cat', 'was', 'held', 'fast', ';', 'and', 'they', 'proceeded']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tokens('merged', 50000) # look at first 50k characters\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[8000:8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Models\n",
    "\n",
    "Train models on the training tokens and test them on the test tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define models to test\n",
    "modelspecs = [\n",
    "    [wp.ngram.NgramModel, {'n':2}],\n",
    "    [wp.ngram.NgramModel, {'n':3}],\n",
    "    [wp.ngram.NgramModel, {'n':4}],\n",
    "    [wp.rnn.RnnModel, {}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntraining_chars 1000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "n-gram (n=2): accuracy = nright/total = 1/180 = 0.005556\n",
      "n-gram (n=3): accuracy = nright/total = 0/179 = 0.000000\n",
      "n-gram (n=4): accuracy = nright/total = 0/178 = 0.000000\n",
      "\n",
      "ntraining_chars 10000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "n-gram (n=2): accuracy = nright/total = 99/1001 = 0.098901\n",
      "n-gram (n=3): accuracy = nright/total = 13/1001 = 0.012987\n",
      "n-gram (n=4): accuracy = nright/total = 3/1001 = 0.002997\n",
      "\n",
      "ntraining_chars 100000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "n-gram (n=2): accuracy = nright/total = 190/1001 = 0.189810\n",
      "n-gram (n=3): accuracy = nright/total = 85/1001 = 0.084915\n",
      "n-gram (n=4): accuracy = nright/total = 14/1001 = 0.013986\n",
      "\n",
      "ntraining_chars 1000000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "n-gram (n=2): accuracy = nright/total = 234/1001 = 0.233766\n",
      "n-gram (n=3): accuracy = nright/total = 133/1001 = 0.132867\n",
      "n-gram (n=4): accuracy = nright/total = 36/1001 = 0.035964\n",
      "\n",
      "ntraining_chars 6000000\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "create model object\n",
      "load model\n",
      "n-gram (n=2): accuracy = nright/total = 239/1001 = 0.238761\n",
      "n-gram (n=3): accuracy = nright/total = 176/1001 = 0.175824\n",
      "n-gram (n=4): accuracy = nright/total = 53/1001 = 0.052947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if output table already exists, skip this step\n",
    "#try:\n",
    "#    rows\n",
    "#except:\n",
    "if 1:\n",
    "    modelfolder = '../../data/models'\n",
    "    #. should be ntraining_tokens\n",
    "    nchars_list = (1000,10000,100000,1000000,6000000)\n",
    "    rows = []\n",
    "    npredictions_max = 1000\n",
    "    k = 3 # predict top k tokens\n",
    "    for nchars in nchars_list:\n",
    "        print('ntraining_chars', nchars)\n",
    "        models = wp.analyze.init_models(modelspecs, modelfolder, data, nchars)\n",
    "        results = wp.analyze.test_models(models, data, npredictions_max, k, nchars)\n",
    "        print()\n",
    "        row = [nchars] + results\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nchars</th>\n",
       "      <th>n-gram (n=2)</th>\n",
       "      <th>n-gram (n=3)</th>\n",
       "      <th>n-gram (n=4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.002997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.189810</td>\n",
       "      <td>0.084915</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.035964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000000</td>\n",
       "      <td>0.238761</td>\n",
       "      <td>0.175824</td>\n",
       "      <td>0.052947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nchars  n-gram (n=2)  n-gram (n=3)  n-gram (n=4)\n",
       "0     1000      0.005556      0.000000      0.000000\n",
       "1    10000      0.098901      0.012987      0.002997\n",
       "2   100000      0.189810      0.084915      0.013986\n",
       "3  1000000      0.233766      0.132867      0.035964\n",
       "4  6000000      0.238761      0.175824      0.052947"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nchars'] + [model.name for model in models]\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>1000000</th>\n",
       "      <th>6000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n-gram (n=2)</th>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.189810</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.238761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-gram (n=3)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.084915</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.175824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-gram (n=4)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.052947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1000      10000     100000    1000000   6000000\n",
       "n-gram (n=2)  0.005556  0.098901  0.189810  0.233766  0.238761\n",
       "n-gram (n=3)  0.000000  0.012987  0.084915  0.132867  0.175824\n",
       "n-gram (n=4)  0.000000  0.002997  0.013986  0.035964  0.052947"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = df.transpose()\n",
    "dft.columns = nchars_list\n",
    "dft2 = dft.drop('nchars',axis=0)\n",
    "dft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dft2.columns, dft2.ix[0])\n",
    "plt.plot(dft2.columns, dft2.ix[1])\n",
    "plt.plot(dft2.columns, dft2.ix[2])\n",
    "plt.legend(loc='best')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Training set size (chars)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram (n=2)\n",
      "Hucheloup . `` and whatever , and the Italian , there was no additional contact information about the discovery\n",
      "\n",
      ". Cosette and flung a blow that day , for instance , and blouse , and put the mire\n",
      "\n",
      "And the old stockade . The lip was indubitable -- THE FOUNDATION , your breakfast ? The woman of\n",
      "\n",
      "Jean Valjean really took up , child ! There are together , and a large crack , and ``\n",
      "\n",
      "Unless seen by a third . After descending the young Hawkins , slang for a cutlass . To have\n",
      "\n",
      "Thenceforth , and mock solemnities . It was warming himself on such as with his grandfather and gladly accept\n",
      "\n",
      "Madeleine arrived there were all the neck was not the sister 's the banks of a bore a few\n",
      "\n",
      "'' `` God is subject of them . It was , impressions of grunt of the doctor ? ''\n",
      "\n",
      "Gray with me . His hair nearly as if suddenly withdrawn , autumn ; `` There , then not\n",
      "\n",
      "She opened the brim and terrible quagmire was trying to my fancy it had n't know what may be\n",
      "\n",
      "\n",
      "n-gram (n=3)\n",
      "Zieten putting France to prefer to overthrow the English infantry , particularly as it were , nevertheless . If the\n",
      "\n",
      "Voltairian royalism , a somewhat nervous frame of a fatal slip , in flesh and blood , amid the cries\n",
      "\n",
      "Monsieur my father a copy , or for whatever it was a hopeless state , constructed in the U.S. unless\n",
      "\n",
      "Chateaubriand , named Fauvent . '' Poor old Freddie suddenly appears leading the infant by the adventures before me I\n",
      "\n",
      "Drive it out again on the north side , had fallen asleep over his tracings and sketches . After two\n",
      "\n",
      "Fatal declivity down which was third on his intrinsic worth , and saw that he would obtain a refund in\n",
      "\n",
      "exclaims Watteau ; Lancret , the squire . `` Have not yet known ; so I feared Mr. Wooster of\n",
      "\n",
      "Joy and pride was shortly to be feared on the ground at the old woman , who saw him no\n",
      "\n",
      "Blcher ordered Blow to attack us . Here was another , to such an authority in reference to what Boulatruelle\n",
      "\n",
      "Dry happiness resembles the voice of the choir , as strange as anything that was easy to inspire my pupils\n",
      "\n",
      "\n",
      "n-gram (n=4)\n",
      "Zieten putting France to the sword by Ponsonby ; his battery of seven pieces spiked ; the Prince of Saxe-Weimar holding\n",
      "\n",
      "Voltairian royalism , a quaint variety , had a desire to take a taxi down to Park Row ! '' Jeeves\n",
      "\n",
      "Monsieur my father , or , as it were , predestined , and which distinguishes the leonine from the aquiline race\n",
      "\n",
      "Chateaubriand , had he not given his five francs to the old man . '' `` And my boots . ''\n",
      "\n",
      "Drive it out better . The glass must be violet for iron jewellery , and black for gold jewellery . Spain\n",
      "\n",
      "Fatal declivity down which the most frequently recurring were -- You shant have her ; he ! he ! Look at\n",
      "\n",
      "exclaims Watteau ; Lancret , the painter 's gamin is called the balloon . On the ground floor as well as\n",
      "\n",
      "Joy and pride in his sons overcame his sorrow at their loss . On me he heaped every kindness that heart\n",
      "\n",
      "Blcher ordered extermination . Roguet had set the lugubrious example of threatening with death any French grenadier who should bring him\n",
      "\n",
      "Dry happiness resembles dry bread . One eats , but one morning she out of her bed , saying to the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "k = 20 # number of words to generate per sequence\n",
    "nsequences = 10\n",
    "for model in models:\n",
    "    print(model.name)\n",
    "    for seed in range(nsequences):\n",
    "        random.seed(seed)\n",
    "        tokens = model.generate(k)\n",
    "        if tokens:\n",
    "            s = ' '.join(tokens)\n",
    "            print(s)\n",
    "            print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
