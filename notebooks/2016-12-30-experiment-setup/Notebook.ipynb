{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word Prediction using Recurrent Neural Networks (RNNs)\n",
    "## Experiment 2016-12-30\n",
    "\n",
    "Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize\n",
    "2. Prepare Data\n",
    "3. Explore Data\n",
    "4. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import python modules\n",
    "from __future__ import print_function, division\n",
    "import os.path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries (slow)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import our wp modules\n",
    "import sys; sys.path.append('../../src')\n",
    "import wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reload wp modules in case changed (for development purposes)\n",
    "reload(wp)\n",
    "reload(wp.data)\n",
    "reload(wp.util)\n",
    "reload(wp.model)\n",
    "reload(wp.ngram)\n",
    "reload(wp.rnn)\n",
    "reload(wp.experiment);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and merge raw text files, split into train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get wrapper around all data and tokenization\n",
    "data = wp.data.Data('gutenbergs')\n",
    "\n",
    "# clean, merge, split files\n",
    "data.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean the raw data files - remove Gutenberg headers and footers, and non-ascii characters (nltk complains otherwise).\n",
    "#data.clean()\n",
    "\n",
    "# merge the cleaned data files into one.\n",
    "#data.merge()\n",
    "\n",
    "# split the merged file by sentences into train, validate, and test sets.\n",
    "#data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# slow\n",
    "stats = data.analyze()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show sentence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsentences = 100\n",
    "nwordsmax = 100\n",
    "df = data.histogram(nsentences, nwordsmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=0,ascending=False).T.boxplot(vert=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.xlabel('Words/Sentence')\n",
    "plt.xlim([0, nwordsmax])\n",
    "sns.swarmplot(data=df.T, orient='h', split=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some samples of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_merged = data.text('merged')\n",
    "nsamples = 4\n",
    "nchars = len(s_merged)\n",
    "nskip = int(nchars / nsamples)\n",
    "for i in range(nsamples):\n",
    "    s = s_merged[i*nskip:i*nskip+200]\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some text split into sentences\n",
    "\n",
    "This shows how the text was split up into the train, validate, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we'll just look at the first 50k characters, because parsing sentences is slow\n",
    "sentences = data.sentences('merged', 50000)\n",
    "random.seed(2)\n",
    "samples = random.sample(sentences, 4)\n",
    "print('\\n\\n'.join(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the text split into tokens\n",
    "\n",
    "Note that punctuation marks are treated as separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokens = data.tokens('merged', 50000)\n",
    "print('ntokens',len(tokens))\n",
    "print(tokens[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments\n",
    "\n",
    "Conduct some experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test models on some test data\n",
    "\n",
    "After preparing the 6mb of Gutenberg data, let's test out the models with a much smaller dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = wp.data.Data('animals')\n",
    "data.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define models to train and test\n",
    "model_specs = [\n",
    "    [wp.ngram.Ngram, {'n':1}],\n",
    "    [wp.ngram.Ngram, {'n':2}],\n",
    "    [wp.ngram.Ngram, {'n':3}],\n",
    "    [wp.ngram.Ngram, {'n':4}],\n",
    "    [wp.rnn.Rnn, {'nvocabmax':10,'nhidden':10}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define parameters to run experiments on\n",
    "params = {'train_amount':[0.5, 1.0]}\n",
    "\n",
    "# create experiment\n",
    "exper = wp.experiment.Experiment(model_specs, data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run it\n",
    "exper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compare n-gram performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define models to train and test\n",
    "model_specs = [\n",
    "    [wp.ngram.Ngram, {'n':1}],\n",
    "    [wp.ngram.Ngram, {'n':2}],\n",
    "    [wp.ngram.Ngram, {'n':3}],\n",
    "    [wp.ngram.Ngram, {'n':4}],\n",
    "    [wp.rnn.Rnn, {'nvocabmax':1000,'nhidden':100}],\n",
    "    [wp.rnn.Rnn, {'nvocabmax':10,'nhidden':10}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train models on different amounts of training data\n",
    "\n",
    "train_amounts = [0.0001, 0.001, 0.01, 0.1, 1.0] # fraction of total training data\n",
    "\n",
    "#nchars_list = [1000]#,10000,100000]#,1000000,6000000]\n",
    "model_table = wp.analyze.init_model_table(model_specs, data, nchars_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Models\n",
    "\n",
    "Test all models on held-out test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test all models and save results to a pandas dataframe\n",
    "\n",
    "ntest_chars = 10000\n",
    "npredictions_max = 1000\n",
    "k = 3 # predict top k tokens\n",
    "\n",
    "df = wp.analyze.test_model_table(model_table, data, ntest_chars, npredictions_max, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(df.index)):\n",
    "    ix_i = df.ix[i]\n",
    "    plt.plot(df.columns, ix_i)\n",
    "plt.legend(loc=(1.1,0.5))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Training set size (chars)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsentences = 5\n",
    "models = model_table[-1] # use models with most training data\n",
    "for model in models[1:]:\n",
    "    print(model.name)\n",
    "    print('-'*80)\n",
    "    for seed in range(nsentences):\n",
    "        random.seed(seed)\n",
    "        s = model.generate()\n",
    "        print(s)\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
